{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "## Vdovenko Anton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, roc_auc_score, precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, VotingClassifier, StackingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loanStats = pd.read_csv('LoanStats_2016Q4.csv', skiprows = 1)\n",
    "rejectStats = pd.read_csv('RejectStats_2016Q4.csv', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103548, 144)\n",
      "Index(['id', 'member_id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv',\n",
      "       'term', 'int_rate', 'installment', 'grade', 'sub_grade',\n",
      "       ...\n",
      "       'orig_projected_additional_accrued_interest',\n",
      "       'hardship_payoff_balance_amount', 'hardship_last_payment_amount',\n",
      "       'debt_settlement_flag', 'debt_settlement_flag_date',\n",
      "       'settlement_status', 'settlement_date', 'settlement_amount',\n",
      "       'settlement_percentage', 'settlement_term'],\n",
      "      dtype='object', length=144)\n"
     ]
    }
   ],
   "source": [
    "print(loanStats.shape)\n",
    "print(loanStats.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1404490, 9)\n",
      "Index(['Amount Requested', 'Application Date', 'Loan Title', 'Risk_Score',\n",
      "       'Debt-To-Income Ratio', 'Zip Code', 'State', 'Employment Length',\n",
      "       'Policy Code'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(rejectStats.shape)\n",
    "print(rejectStats.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>orig_projected_additional_accrued_interest</th>\n",
       "      <th>hardship_payoff_balance_amount</th>\n",
       "      <th>hardship_last_payment_amount</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "      <th>debt_settlement_flag_date</th>\n",
       "      <th>settlement_status</th>\n",
       "      <th>settlement_date</th>\n",
       "      <th>settlement_amount</th>\n",
       "      <th>settlement_percentage</th>\n",
       "      <th>settlement_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103545</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>14.49%</td>\n",
       "      <td>329.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103546</th>\n",
       "      <td>Total amount funded in policy code 1: 1465324575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103547</th>\n",
       "      <td>Total amount funded in policy code 2: 521953170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      id  member_id  \\\n",
       "103545                                               NaN        NaN   \n",
       "103546  Total amount funded in policy code 1: 1465324575        NaN   \n",
       "103547   Total amount funded in policy code 2: 521953170        NaN   \n",
       "\n",
       "        loan_amnt  funded_amnt  funded_amnt_inv        term int_rate  \\\n",
       "103545    14000.0      14000.0          14000.0   60 months   14.49%   \n",
       "103546        NaN          NaN              NaN         NaN      NaN   \n",
       "103547        NaN          NaN              NaN         NaN      NaN   \n",
       "\n",
       "        installment grade sub_grade  ...  \\\n",
       "103545       329.33     C        C4  ...   \n",
       "103546          NaN   NaN       NaN  ...   \n",
       "103547          NaN   NaN       NaN  ...   \n",
       "\n",
       "       orig_projected_additional_accrued_interest  \\\n",
       "103545                                        NaN   \n",
       "103546                                        NaN   \n",
       "103547                                        NaN   \n",
       "\n",
       "       hardship_payoff_balance_amount hardship_last_payment_amount  \\\n",
       "103545                            NaN                          NaN   \n",
       "103546                            NaN                          NaN   \n",
       "103547                            NaN                          NaN   \n",
       "\n",
       "        debt_settlement_flag debt_settlement_flag_date settlement_status  \\\n",
       "103545                     N                       NaN               NaN   \n",
       "103546                   NaN                       NaN               NaN   \n",
       "103547                   NaN                       NaN               NaN   \n",
       "\n",
       "       settlement_date settlement_amount  settlement_percentage  \\\n",
       "103545             NaN               NaN                    NaN   \n",
       "103546             NaN               NaN                    NaN   \n",
       "103547             NaN               NaN                    NaN   \n",
       "\n",
       "       settlement_term  \n",
       "103545             NaN  \n",
       "103546             NaN  \n",
       "103547             NaN  \n",
       "\n",
       "[3 rows x 144 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loanStats[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop last two rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loanStats = loanStats.drop(loanStats.index[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop first two columns since they are empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'member_id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv',\n",
       "       'term', 'int_rate', 'installment', 'grade', 'sub_grade',\n",
       "       ...\n",
       "       'orig_projected_additional_accrued_interest',\n",
       "       'hardship_payoff_balance_amount', 'hardship_last_payment_amount',\n",
       "       'debt_settlement_flag', 'debt_settlement_flag_date',\n",
       "       'settlement_status', 'settlement_date', 'settlement_amount',\n",
       "       'settlement_percentage', 'settlement_term'],\n",
       "      dtype='object', length=144)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loanStats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loanStats = loanStats.drop(['id', 'member_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103546, 142)\n",
      "Index(['loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'term', 'int_rate',\n",
      "       'installment', 'grade', 'sub_grade', 'emp_title', 'emp_length',\n",
      "       ...\n",
      "       'orig_projected_additional_accrued_interest',\n",
      "       'hardship_payoff_balance_amount', 'hardship_last_payment_amount',\n",
      "       'debt_settlement_flag', 'debt_settlement_flag_date',\n",
      "       'settlement_status', 'settlement_date', 'settlement_amount',\n",
      "       'settlement_percentage', 'settlement_term'],\n",
      "      dtype='object', length=142)\n",
      "(1404490, 9)\n",
      "Index(['Amount Requested', 'Application Date', 'Loan Title', 'Risk_Score',\n",
      "       'Debt-To-Income Ratio', 'Zip Code', 'State', 'Employment Length',\n",
      "       'Policy Code'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(loanStats.shape)\n",
    "print(loanStats.columns)\n",
    "print(rejectStats.shape)\n",
    "print(rejectStats.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    103546.000000\n",
      "mean      14151.435835\n",
      "std        9215.032376\n",
      "min        1000.000000\n",
      "25%        7000.000000\n",
      "50%       12000.000000\n",
      "75%       20000.000000\n",
      "max       40000.000000\n",
      "Name: loan_amnt, dtype: float64\n",
      "count    1.404490e+06\n",
      "mean     1.293313e+04\n",
      "std      1.567272e+04\n",
      "min      0.000000e+00\n",
      "25%      4.000000e+03\n",
      "50%      1.000000e+04\n",
      "75%      2.000000e+04\n",
      "max      3.000000e+05\n",
      "Name: Amount Requested, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(loanStats['loan_amnt'].describe())\n",
    "print(rejectStats['Amount Requested'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debt consolidation         59749\n",
      "Credit card refinancing    20528\n",
      "Home improvement            7393\n",
      "Other                       7383\n",
      "Major purchase              2470\n",
      "Medical expenses            1468\n",
      "Business                    1216\n",
      "Car financing               1162\n",
      "Vacation                     829\n",
      "Moving and relocation        772\n",
      "Home buying                  475\n",
      "Green loan                    97\n",
      "Name: title, dtype: int64\n",
      "debt_consolidation         359782\n",
      "Debt consolidation         324415\n",
      "other                      146389\n",
      "credit_card                 96179\n",
      "Other                       71882\n",
      "Credit card refinancing     67381\n",
      "home_improvement            44136\n",
      "Home improvement            31054\n",
      "car                         29480\n",
      "major_purchase              29301\n",
      "Car financing               22788\n",
      "moving                      20836\n",
      "medical                     20814\n",
      "Medical expenses            19315\n",
      "Business Loan               18575\n",
      "Moving and relocation       17616\n",
      "Major purchase              17505\n",
      "Business                    13845\n",
      "small_business              13410\n",
      "house                       11088\n",
      "vacation                     9842\n",
      "Vacation                     7392\n",
      "Home buying                  7300\n",
      "Green loan                   2075\n",
      "renewable_energy             2009\n",
      "Name: Loan Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(loanStats['title'].value_counts())\n",
    "print(rejectStats['Loan Title'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 9 columns in reject data, let's try to match loan data with reject data:<br/>\n",
    "* 'loan_amnt' in loanStats should match with 'Amount Requested' in rejectStats.\n",
    "* 'issue_d' in loanStats is the issue date, it should be later than 'Application Date' in rejectStats, let's ignore this pair for now.\n",
    "* 'title' in loanStats should match with 'Loan Title' in rejectStats. However, we need to deal with upper/lower case and space/underscore issues.\n",
    "* There is no column in loanStats matches with 'Risk_Score' in rejectStats, would be very useful if there was one.\n",
    "* 'dti' in loanStats matches with 'Debt-To-Income Ratio' in rejectStats.\n",
    "* 'zip_code' and 'addr_state' in loanStats match with 'Zip Code' and 'State' in rejectStats respectively. Zip codes are only available in first 3 digits, and we might need to get external data for the demographics about the zip code.\n",
    "* 'emp_length' in loanStats matches with 'Employment Length' in rejectStats.\n",
    "* 'policy_code' in loanStats matches with 'Policy Code' in rejectStats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10+ years    35981\n",
      "2 years       9652\n",
      "3 years       8244\n",
      "< 1 year      7591\n",
      "1 year        6707\n",
      "5 years       6292\n",
      "4 years       6249\n",
      "6 years       4786\n",
      "8 years       3951\n",
      "9 years       3870\n",
      "7 years       3346\n",
      "Name: emp_length, dtype: int64\n",
      "< 1 year     1022412\n",
      "5 years       274322\n",
      "10+ years      16782\n",
      "2 years         5248\n",
      "3 years         4502\n",
      "1 year          4389\n",
      "4 years         3314\n",
      "6 years         2494\n",
      "8 years         1953\n",
      "7 years         1918\n",
      "9 years         1586\n",
      "Name: Employment Length, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(loanStats['emp_length'].value_counts())\n",
    "print(rejectStats['Employment Length'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    103546\n",
      "Name: policy_code, dtype: int64\n",
      "0    1403661\n",
      "2        829\n",
      "Name: Policy Code, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(loanStats['policy_code'].value_counts())\n",
    "print(rejectStats['Policy Code'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, policy code is useless since it carries different meaning in the two datasets, so we should ignore this pair of columns.<br/>\n",
    "Let's now build two new dataframes, and keep their columns consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved = pd.DataFrame()\n",
    "rejected = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy values from 'loan_amnt' and 'Amount Requested' directly to the new dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved['amount'] = loanStats['loan_amnt']\n",
    "rejected['amount'] = rejectStats['Amount Requested']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using lambda functions to convert strings, first make all characters lower cases, and split them by space, then join them using '\\_'. While joining, remove words like 'and', 'expenses', 'financing', 'loan', 'refinancing', as these words are not important in reasons for loans. To further consolidate the reasons, we merge 'housing' to 'home\\_buying', 'moving' to 'moving\\_relocation', 'renewable\\_energy' to 'green', and 'small\\_business' to 'business'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['and', 'expenses', 'financing', 'loan', 'refinancing']\n",
    "approved['reason'] = loanStats['title'].apply(lambda x: 'other' if type(x) != str else '_'.join([i for i in x.lower().split() if i not in stop_words]))\n",
    "rejected['reason'] = rejectStats['Loan Title'].apply(lambda x: 'other' if type(x) != str else '_'.join([i for i in x.lower().split() if i not in stop_words]))\n",
    "convert = {'house': 'home_buying', 'moving': 'moving_relocation', 'renewable_energy': 'green', 'small_business': 'business'}\n",
    "rejected['reason'] = rejected['reason'].apply(lambda x: convert[x] if x in convert else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy values from 'dti' and 'Debt-To-Income Ratio', however, to identify Not-a-Number floats, we test x == x, in it's a NaN, we set it to the maximum in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved['debt_to_income'] = loanStats['dti'].apply(lambda x: max(0.0, min(x / 100, 1.0)) if x == x else 1.0)\n",
    "rejected['debt_to_income'] = rejectStats['Debt-To-Income Ratio'].apply(lambda x: max(0.0, min(float(x[:-1]) / 100, 1.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep the first 3 digits of the zip codes since the last 2 digits are masked, however, it is unnecessary to convert them to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved['zip3'] = loanStats['zip_code'].apply(lambda x: x[:3] if type(x) == str else 'N/A')\n",
    "rejected['zip3'] = rejectStats['Zip Code'].apply(lambda x: x[:3] if type(x) == str else 'N/A')\n",
    "approved['state'] = loanStats['addr_state']\n",
    "rejected['state'] = rejectStats['State']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the employment length to numerical values, if it is not specified, or less than a year, we take them as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved['employ_length'] = loanStats['emp_length'].apply(lambda x: 0 if type(x) != str or x[:3] == '< 1' else int(x[:2]))\n",
    "rejected['employ_length'] = rejectStats['Employment Length'].apply(lambda x: 0 if type(x) != str or x[:3] == '< 1' else int(x[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column 'reason' is now the only nominal column, we may use function get\\_dummies, drop 'other' is recommended since 'reason\\_=\\_other' is fuzzy, and should be expressed by 0 in all other reason columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved = pd.concat([approved, pd.get_dummies(approved['reason'], prefix = 'reason', prefix_sep = '_=_').drop('reason_=_other', axis = 1)], axis = 1).drop('reason', axis = 1)\n",
    "rejected = pd.concat([rejected, pd.get_dummies(rejected['reason'], prefix = 'reason', prefix_sep = '_=_').drop('reason_=_other', axis = 1)], axis = 1).drop('reason', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the response column to the two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved['approved'] = 1\n",
    "rejected['approved'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the two dataframes to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos = approved.drop(['zip3', 'state'], axis = 1).values\n",
    "data_neg = rejected.drop(['zip3', 'state'], axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103546, 15)\n",
      "(1404490, 15)\n"
     ]
    }
   ],
   "source": [
    "print(data_pos.shape)\n",
    "print(data_neg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Question 1] Build Logistic Regression Models and Naive Bayes Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the two basic classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>employ_length</th>\n",
       "      <th>reason_=_business</th>\n",
       "      <th>reason_=_car</th>\n",
       "      <th>reason_=_credit_card</th>\n",
       "      <th>reason_=_debt_consolidation</th>\n",
       "      <th>reason_=_green</th>\n",
       "      <th>reason_=_home_buying</th>\n",
       "      <th>reason_=_home_improvement</th>\n",
       "      <th>reason_=_major_purchase</th>\n",
       "      <th>reason_=_medical</th>\n",
       "      <th>reason_=_moving_relocation</th>\n",
       "      <th>reason_=_vacation</th>\n",
       "      <th>approved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.2993</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount  debt_to_income  employ_length  reason_=_business  reason_=_car  \\\n",
       "0  4500.0          0.2993              6                  0             0   \n",
       "\n",
       "   reason_=_credit_card  reason_=_debt_consolidation  reason_=_green  \\\n",
       "0                     1                            0               0   \n",
       "\n",
       "   reason_=_home_buying  reason_=_home_improvement  reason_=_major_purchase  \\\n",
       "0                     0                          0                        0   \n",
       "\n",
       "   reason_=_medical  reason_=_moving_relocation  reason_=_vacation  approved  \n",
       "0                 0                           0                  0         1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.concat([approved,rejected])\n",
    "merged = merged.drop([\"zip3\",\"state\"], axis = 1)\n",
    "merged.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = merged.iloc[:,:-1]\n",
    "y = merged[\"approved\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_recall : 0.45\n",
      "score_time : 0.53\n",
      "test_precision : 0.68\n",
      "test_f1 : 0.54\n",
      "test_accuracy : 0.95\n",
      "fit_time : 0.45\n",
      "test_roc_auc : 0.84\n",
      "f_beta: 0.62 beta: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "clf = GaussianNB()\n",
    "scores = cross_validate(clf, x, y, cv=5,\n",
    "                        scoring=('accuracy', 'f1', \"roc_auc\",\"precision\",\"recall\"))\n",
    "                        \n",
    "for i in scores:\n",
    "    print(i,\":\",scores[i].mean().round(2))\n",
    "b = 0.5\n",
    "f_beta = (1 + b**2) * ((scores[\"test_precision\"].mean()*scores[\"test_recall\"].mean())/((b**2 * scores[\"test_precision\"].mean()) + scores[\"test_recall\"].mean()))\n",
    "print(\"f_beta:\",f_beta.round(2),\"beta:\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_beta: 0.63 beta: 0.5\n",
      "                      0\n",
      "accuracy       0.949097\n",
      "recall         0.479468\n",
      "precision      0.680983\n",
      "roc_auc_score  0.731500\n"
     ]
    }
   ],
   "source": [
    "# Chosse Threshold to max Fb\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "THRESHOLD = 0.4\n",
    "preds = np.where(clf.predict_proba(X_test)[:,1] > THRESHOLD, 1, 0)\n",
    "\n",
    "z = pd.DataFrame(data=[accuracy_score(y_test, preds), recall_score(y_test, preds),\n",
    "                   precision_score(y_test, preds), roc_auc_score(y_test, preds)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"roc_auc_score\"])\n",
    "b = 0.5\n",
    "f_beta = (1 + b**2) * ((precision_score(y_test, preds)*recall_score(y_test, preds))/((b**2 * precision_score(y_test, preds)) + recall_score(y_test, preds)))\n",
    "print(\"f_beta:\",f_beta.round(2),\"beta:\",b)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distributions = dict(C = scipy.stats.uniform(loc=0, scale=4),penalty=['l2'])\n",
    "# logistic = LogisticRegression(random_state = 0)\n",
    "# clf = RandomizedSearchCV(logistic, distributions, random_state=0)\n",
    "# search = clf.fit(x, y)\n",
    "# search.best_params_\n",
    "# C = 3.567092003128319"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_recall : 0.33\n",
      "score_time : 0.36\n",
      "test_precision : 0.7\n",
      "test_f1 : 0.45\n",
      "test_accuracy : 0.94\n",
      "fit_time : 5.45\n",
      "test_roc_auc : 0.85\n",
      "f_beta: 0.58 beta: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Classifier\n",
    "x_scaled = MinMaxScaler().fit_transform(x)\n",
    "\n",
    "clf = LogisticRegression(C = 3.567092003128319, random_state=0)\n",
    "scores = cross_validate(clf, x_scaled, y, cv=5,\n",
    "                        scoring=('accuracy', 'f1', \"roc_auc\",\"precision\",\"recall\"))\n",
    "                        \n",
    "for i in scores:\n",
    "    print(i,\":\",scores[i].mean().round(2))\n",
    "b = 0.5\n",
    "f_beta = (1 + b**2) * ((scores[\"test_precision\"].mean()*scores[\"test_recall\"].mean())/((b**2 * scores[\"test_precision\"].mean()) + scores[\"test_recall\"].mean()))\n",
    "print(\"f_beta:\",f_beta.round(2),\"beta:\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_beta: 0.62 beta: 0.5\n",
      "                      0\n",
      "accuracy       0.948259\n",
      "recall         0.490617\n",
      "precision      0.664211\n",
      "roc_auc_score  0.736215\n"
     ]
    }
   ],
   "source": [
    "# Chosse Threshold to max Fb\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(class_weight=\"balanced\",C = 3.567092003128319, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "THRESHOLD = 0.75\n",
    "preds = np.where(clf.predict_proba(X_test)[:,1] > THRESHOLD, 1, 0)\n",
    "\n",
    "z = pd.DataFrame(data=[accuracy_score(y_test, preds), recall_score(y_test, preds),\n",
    "                   precision_score(y_test, preds), roc_auc_score(y_test, preds)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"roc_auc_score\"])\n",
    "b = 0.5\n",
    "f_beta = (1 + b**2) * ((precision_score(y_test, preds)*recall_score(y_test, preds))/((b**2 * precision_score(y_test, preds)) + recall_score(y_test, preds)))\n",
    "print(\"f_beta:\",f_beta.round(2),\"beta:\",b)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  | Logistic Regression with C = 3.6   |Naive Bayes  |\n",
    "|------|------|-----|\n",
    "|   Precision | 0.7|0.68|\n",
    "|   Recall | 0.33|0.45|\n",
    "|   Chosen Beta | 0.5|\n",
    "|   Fb | 0.58|0.62|\n",
    "|   AUC under ROC | 0.85|0.84|\n",
    "\n",
    "|  | Logistic Regression with Treshold 0.75|Naive Bayes with Treshold 0.4  |\n",
    "|------|------|-----|\n",
    "|   Precision | 0.66|0.68|\n",
    "|   Recall | 0.49|0.48|\n",
    "|   Chosen Beta | 0.5|\n",
    "|   Fb | 0.62|0.63|\n",
    "|   AUC under ROC | 0.74|0.73|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision = TP/(TP+FP), Recall = TP/(TP + FN). False Positive is the case we give money to someone you shouldn't\n",
    "# and most likely face huge loss, False Negative is the case we didnt give money to someone we should have and miss profit.\n",
    "# Both are important but having as less loss as possible is crucial so we prioritize having less False Positives\n",
    "# and hence high Precision. For F Beta score standard practice when we put more importance to Precision is to choose value\n",
    "# of beta = 0.5. When we look at our final table we can see that AUC is close to equal in both models, but Naive Bayes\n",
    "# has higher Fb score, hence we choose Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Question 2] Build Classification Models over GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build GMM models + classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes:\n",
      "test_recall : 0.47\n",
      "score_time : 0.55\n",
      "test_precision : 0.69\n",
      "test_f1 : 0.55\n",
      "test_accuracy : 0.95\n",
      "fit_time : 0.47\n",
      "test_roc_auc : 0.84\n",
      "f_beta: 0.63 beta: 0.5\n"
     ]
    }
   ],
   "source": [
    "# GaussianMixture 5 classes for NB\n",
    "\n",
    "gmm = GaussianMixture(n_components=5, random_state=0).fit_predict(x)\n",
    "clusters = pd.DataFrame(gmm,columns=[\"cluster\"])\n",
    "X = pd.merge(x,clusters, on=[x.index,clusters.index])\n",
    "X = X.drop([\"key_0\",\"key_1\"], axis=1)\n",
    "\n",
    "# Naive Bayes on 5 Clusters\n",
    "\n",
    "clf = GaussianNB()\n",
    "scores = cross_validate(clf, X, y, cv=5,\n",
    "                        scoring=('accuracy', 'f1', \"roc_auc\",\"precision\",\"recall\"))\n",
    "print(\"Naive Bayes:\")                        \n",
    "for i in scores:\n",
    "    print(i,\":\",scores[i].mean().round(2))\n",
    "b = 0.5\n",
    "f_beta = (1 + b**2) * ((scores[\"test_precision\"].mean()*scores[\"test_recall\"].mean())/((b**2 * scores[\"test_precision\"].mean()) + scores[\"test_recall\"].mean()))\n",
    "print(\"f_beta:\",f_beta.round(2),\"beta:\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes:\n",
      "test_recall : 0.46\n",
      "score_time : 0.53\n",
      "test_precision : 0.69\n",
      "test_f1 : 0.55\n",
      "test_accuracy : 0.95\n",
      "fit_time : 0.47\n",
      "test_roc_auc : 0.84\n",
      "f_beta: 0.63 beta: 0.5\n"
     ]
    }
   ],
   "source": [
    "# GaussianMixture 10 classes for NB\n",
    "\n",
    "gmm = GaussianMixture(n_components=10, random_state=0).fit_predict(x)\n",
    "clusters = pd.DataFrame(gmm,columns=[\"cluster\"])\n",
    "X = pd.merge(x,clusters, on=[x.index,clusters.index])\n",
    "X = X.drop([\"key_0\",\"key_1\"], axis=1)\n",
    "\n",
    "# Naive Bayes on 5 Clusters\n",
    "\n",
    "clf = GaussianNB()\n",
    "scores = cross_validate(clf, X, y, cv=5,\n",
    "                        scoring=('accuracy', 'f1', \"roc_auc\",\"precision\",\"recall\"))\n",
    "print(\"Naive Bayes:\")                        \n",
    "for i in scores:\n",
    "    print(i,\":\",scores[i].mean().round(2))\n",
    "b = 0.5\n",
    "f_beta = (1 + b**2) * ((scores[\"test_precision\"].mean()*scores[\"test_recall\"].mean())/((b**2 * scores[\"test_precision\"].mean()) + scores[\"test_recall\"].mean()))\n",
    "print(\"f_beta:\",f_beta.round(2),\"beta:\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes:\n",
      "test_recall : 0.46\n",
      "score_time : 0.54\n",
      "test_precision : 0.69\n",
      "test_f1 : 0.55\n",
      "test_accuracy : 0.95\n",
      "fit_time : 0.46\n",
      "test_roc_auc : 0.84\n",
      "f_beta: 0.63 beta: 0.5\n"
     ]
    }
   ],
   "source": [
    "# GaussianMixture 20 classes for NB\n",
    "\n",
    "gmm = GaussianMixture(n_components=20, random_state=0).fit_predict(x)\n",
    "clusters = pd.DataFrame(gmm,columns=[\"cluster\"])\n",
    "X = pd.merge(x,clusters, on=[x.index,clusters.index])\n",
    "X = X.drop([\"key_0\",\"key_1\"], axis=1)\n",
    "\n",
    "# Naive Bayes on 5 Clusters\n",
    "\n",
    "clf = GaussianNB()\n",
    "scores = cross_validate(clf, X, y, cv=5,\n",
    "                        scoring=('accuracy', 'f1', \"roc_auc\",\"precision\",\"recall\"))\n",
    "print(\"Naive Bayes:\")                        \n",
    "for i in scores:\n",
    "    print(i,\":\",scores[i].mean().round(2))\n",
    "b = 0.5\n",
    "f_beta = (1 + b**2) * ((scores[\"test_precision\"].mean()*scores[\"test_recall\"].mean())/((b**2 * scores[\"test_precision\"].mean()) + scores[\"test_recall\"].mean()))\n",
    "print(\"f_beta:\",f_beta.round(2),\"beta:\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "test_recall : 0.33\n",
      "score_time : 0.35\n",
      "test_precision : 0.7\n",
      "test_f1 : 0.45\n",
      "test_accuracy : 0.94\n",
      "fit_time : 5.58\n",
      "test_roc_auc : 0.85\n",
      "f_beta: 0.58 beta: 0.5\n"
     ]
    }
   ],
   "source": [
    "# GaussianMixture 5 classes for LR\n",
    "x_scaled = StandardScaler().fit_transform(x)\n",
    "gmm = GaussianMixture(n_components=5, random_state=0).fit_predict(x_scaled)\n",
    "clusters = pd.DataFrame(gmm,columns=[\"cluster\"])\n",
    "X = pd.merge(x,clusters, on=[x.index,clusters.index])\n",
    "X = X.drop([\"key_0\",\"key_1\"], axis=1)\n",
    "\n",
    "# Logistic Regression Classifier on 5 Clusters\n",
    "x_scaled = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "clf = LogisticRegression(C = 3.567092003128319, random_state=0)\n",
    "scores = cross_validate(clf, x_scaled, y, cv=5,\n",
    "                        scoring=('accuracy', 'f1', \"roc_auc\",\"precision\",\"recall\"))\n",
    "\n",
    "print(\"Logistic Regression:\")                        \n",
    "for i in scores:\n",
    "    print(i,\":\",scores[i].mean().round(2))\n",
    "b = 0.5\n",
    "f_beta = (1 + b**2) * ((scores[\"test_precision\"].mean()*scores[\"test_recall\"].mean())/((b**2 * scores[\"test_precision\"].mean()) + scores[\"test_recall\"].mean()))\n",
    "print(\"f_beta:\",f_beta.round(2),\"beta:\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "test_recall : 0.29\n",
      "score_time : 0.36\n",
      "test_precision : 0.7\n",
      "test_f1 : 0.41\n",
      "test_accuracy : 0.94\n",
      "fit_time : 5.69\n",
      "test_roc_auc : 0.87\n",
      "f_beta: 0.55 beta: 0.5\n"
     ]
    }
   ],
   "source": [
    "# GaussianMixture 10 classes for LR\n",
    "x_scaled = StandardScaler().fit_transform(x)\n",
    "gmm = GaussianMixture(n_components=10, random_state=0).fit_predict(x_scaled)\n",
    "clusters = pd.DataFrame(gmm,columns=[\"cluster\"])\n",
    "X = pd.merge(x,clusters, on=[x.index,clusters.index])\n",
    "X = X.drop([\"key_0\",\"key_1\"], axis=1)\n",
    "\n",
    "# Logistic Regression Classifier on 5 Clusters\n",
    "x_scaled = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "clf = LogisticRegression(C = 3.567092003128319, random_state=0)\n",
    "scores = cross_validate(clf, x_scaled, y, cv=5,\n",
    "                        scoring=('accuracy', 'f1', \"roc_auc\",\"precision\",\"recall\"))\n",
    "\n",
    "print(\"Logistic Regression:\")                        \n",
    "for i in scores:\n",
    "    print(i,\":\",scores[i].mean().round(2))\n",
    "b = 0.5\n",
    "f_beta = (1 + b**2) * ((scores[\"test_precision\"].mean()*scores[\"test_recall\"].mean())/((b**2 * scores[\"test_precision\"].mean()) + scores[\"test_recall\"].mean()))\n",
    "print(\"f_beta:\",f_beta.round(2),\"beta:\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "test_recall : 0.33\n",
      "score_time : 0.34\n",
      "test_precision : 0.7\n",
      "test_f1 : 0.45\n",
      "test_accuracy : 0.94\n",
      "fit_time : 6.19\n",
      "test_roc_auc : 0.85\n",
      "f_beta: 0.58 beta: 0.5\n"
     ]
    }
   ],
   "source": [
    "# GaussianMixture 20 classes for LR\n",
    "x_scaled = StandardScaler().fit_transform(x)\n",
    "gmm = GaussianMixture(n_components=20, random_state=0).fit_predict(x_scaled)\n",
    "clusters = pd.DataFrame(gmm,columns=[\"cluster\"])\n",
    "X = pd.merge(x,clusters, on=[x.index,clusters.index])\n",
    "X = X.drop([\"key_0\",\"key_1\"], axis=1)\n",
    "\n",
    "# Logistic Regression Classifier on 5 Clusters\n",
    "x_scaled = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "clf = LogisticRegression(C = 3.567092003128319, random_state=0)\n",
    "scores = cross_validate(clf, x_scaled, y, cv=5,\n",
    "                        scoring=('accuracy', 'f1', \"roc_auc\",\"precision\",\"recall\"))\n",
    "\n",
    "print(\"Logistic Regression:\")                        \n",
    "for i in scores:\n",
    "    print(i,\":\",scores[i].mean().round(2))\n",
    "b = 0.5\n",
    "f_beta = (1 + b**2) * ((scores[\"test_precision\"].mean()*scores[\"test_recall\"].mean())/((b**2 * scores[\"test_precision\"].mean()) + scores[\"test_recall\"].mean()))\n",
    "print(\"f_beta:\",f_beta.round(2),\"beta:\",b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  |    |Logistic Regression With C=3.6  |Naive Bayes  |\n",
    "|------|------|-----|-----|\n",
    "|    | Precision|0.7|0.69|\n",
    "|    | Recall|0.33|0.47|\n",
    "| 5 clusters   | Fb b=0.5|0.58|0.63|\n",
    "|    | AUC under ROC|0.85|0.84|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  |    |Logistic Regression With C=3.6  |Naive Bayes  |\n",
    "|------|------|-----|-----|\n",
    "|    | Precision|0.7|0.69|\n",
    "|    | Recall|0.29|0.46|\n",
    "| 10 clusters   | Fb b=0.5|0.55|0.63|\n",
    "|    | AUC under ROC|0.87|0.84|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  |    |Logistic Regression With C=3.6  |Naive Bayes  |\n",
    "|------|------|-----|-----|\n",
    "|    | Precision|0.7|0.69|\n",
    "|    | Recall|0.33|0.46|\n",
    "| 20 clusters   | Fb b=0.5|0.58|0.63|\n",
    "|    | AUC under ROC|0.85|0.84|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes is very stable the only difference we can see is that Recall droped on 0.01 when number of clusters increased.\n",
    "# Logistic Regression has best AUC with 10 clusters, but best Fb with 5 and 20 clusters. Overall if we compare with Q1\n",
    "# the Naive Bayes model Fb increased by 0.01, a minor performance improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Question 3] Build Ensemble Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=GaussianNB(priors=None, var_smoothing=1e-09),\n",
      "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "                  max_samples=1.0, n_estimators=100, n_jobs=None,\n",
      "                  oob_score=False, random_state=12, verbose=0,\n",
      "                  warm_start=False)\n",
      "test_recall : 0.45\n",
      "score_time : 21.55\n",
      "test_precision : 0.68\n",
      "test_f1 : 0.54\n",
      "test_accuracy : 0.95\n",
      "fit_time : 53.33\n",
      "test_roc_auc : 0.84\n",
      "f_beta: 0.62 beta: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Baggig Naive Bayes Classifier\n",
    "\n",
    "NB_clf = GaussianNB()\n",
    "nb_bagging_model = BaggingClassifier(base_estimator=NB_clf, n_estimators=100, random_state=12)\n",
    "\n",
    "\n",
    "def bagging_ensemble(model):    \n",
    "    scores = cross_validate(model, x, y, cv=5,scoring=('accuracy', 'f1', \"roc_auc\",\"precision\",\"recall\"))\n",
    "    print(model)\n",
    "                          \n",
    "    for i in scores:\n",
    "        print(i,\":\",scores[i].mean().round(2))\n",
    "    \n",
    "    b = 0.5\n",
    "    f_beta = (1 + b**2) * ((scores[\"test_precision\"].mean()*scores[\"test_recall\"].mean())/((b**2 * scores[\"test_precision\"].mean()) + scores        [\"test_recall\"].mean()))\n",
    "     \n",
    "    print(\"f_beta:\",f_beta.round(2),\"beta:\",b)\n",
    "    \n",
    "\n",
    "\n",
    "bagging_ensemble(nb_bagging_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=LogisticRegression(C=3.567092003128319),\n",
      "                  n_estimators=5, random_state=12)\n",
      "fit_time : 45.22\n",
      "score_time : 1.2\n",
      "test_accuracy : 0.94\n",
      "test_f1 : 0.45\n",
      "test_roc_auc : 0.85\n",
      "test_precision : 0.7\n",
      "test_recall : 0.33\n",
      "f_beta: 0.57 beta: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Bagging Logistic Regression Classifier\n",
    "x_scaled = MinMaxScaler().fit_transform(x)\n",
    "LogReg_clf = LogisticRegression(C = 3.567092003128319)\n",
    "\n",
    "logreg_bagging_model = BaggingClassifier(base_estimator=LogReg_clf, n_estimators=5, random_state=12)\n",
    "\n",
    "\n",
    "def bagging_ensemble(model):\n",
    "    \n",
    "    scores = cross_validate(model, x_scaled, y, cv=5,scoring=('accuracy', 'f1', \"roc_auc\",\"precision\",\"recall\"))\n",
    "    print(model)\n",
    "                          \n",
    "    for i in scores:\n",
    "        print(i,\":\",scores[i].mean().round(2))\n",
    "    \n",
    "    b = 0.5\n",
    "    f_beta = (1 + b**2) * ((scores[\"test_precision\"].mean()*scores[\"test_recall\"].mean())/((b**2 * scores[\"test_precision\"].mean()) + scores        [\"test_recall\"].mean()))\n",
    "     \n",
    "    print(\"f_beta:\",f_beta.round(2),\"beta:\",b)\n",
    "    \n",
    "\n",
    "bagging_ensemble(logreg_bagging_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
      "                                                        class_weight=None,\n",
      "                                                        criterion='gini',\n",
      "                                                        max_depth=None,\n",
      "                                                        max_features=None,\n",
      "                                                        max_leaf_nodes=None,\n",
      "                                                        min_impurity_decrease=0.0,\n",
      "                                                        min_impurity_split=None,\n",
      "                                                        min_samples_leaf=1,\n",
      "                                                        min_samples_split=2,\n",
      "                                                        min_weight_fraction_leaf=0.0,\n",
      "                                                        presort='deprecated',\n",
      "                                                        random_state=None,\n",
      "                                                        splitter='best'),\n",
      "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "                  max_samples=1.0, n_estimators=50, n_jobs=None,\n",
      "                  oob_score=False, random_state=12, verbose=0,\n",
      "                  warm_start=False)\n",
      "test_recall : 0.64\n",
      "score_time : 8.85\n",
      "test_precision : 0.68\n",
      "test_f1 : 0.66\n",
      "test_accuracy : 0.95\n",
      "fit_time : 229.39\n",
      "test_roc_auc : 0.92\n",
      "f_beta: 0.67 beta: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Bagging Decesion Tree Classifier\n",
    "\n",
    "\n",
    "DTree_clf = DecisionTreeClassifier()\n",
    "\n",
    "dtree_bagging_model = BaggingClassifier(base_estimator=DTree_clf, n_estimators=50, random_state=12)\n",
    "\n",
    "\n",
    "def bagging_ensemble(model):\n",
    "    \n",
    "    scores = cross_validate(model, x, y, cv=5,scoring=('accuracy', 'f1', \"roc_auc\",\"precision\",\"recall\"))\n",
    "    print(model)\n",
    "                          \n",
    "    for i in scores:\n",
    "        print(i,\":\",scores[i].mean().round(2))\n",
    "    \n",
    "    b = 0.5\n",
    "    f_beta = (1 + b**2) * ((scores[\"test_precision\"].mean()*scores[\"test_recall\"].mean())/((b**2 * scores[\"test_precision\"].mean()) + scores        [\"test_recall\"].mean()))\n",
    "     \n",
    "    print(\"f_beta:\",f_beta.round(2),\"beta:\",b)\n",
    "    \n",
    "\n",
    "\n",
    "bagging_ensemble(dtree_bagging_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier(random_state=12)\n",
      "fit_time : 105.38\n",
      "score_time : 17.89\n",
      "test_accuracy : 0.95\n",
      "test_f1 : 0.64\n",
      "test_roc_auc : 0.9\n",
      "test_precision : 0.67\n",
      "test_recall : 0.61\n",
      "f_beta: 0.65 beta: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees Classifier\n",
    "\n",
    "extra_trees = ExtraTreesClassifier(n_estimators=100, random_state=12)\n",
    "\n",
    "def bagging_ensemble(model):\n",
    "    \n",
    "    scores = cross_validate(model, x, y, cv=5,scoring=('accuracy', 'f1', \"roc_auc\",\"precision\",\"recall\"))\n",
    "    print(model)\n",
    "                          \n",
    "    for i in scores:\n",
    "        print(i,\":\",scores[i].mean().round(2))\n",
    "    \n",
    "    b = 0.5\n",
    "    f_beta = (1 + b**2) * ((scores[\"test_precision\"].mean()*scores[\"test_recall\"].mean())/((b**2 * scores[\"test_precision\"].mean()) + scores        [\"test_recall\"].mean()))\n",
    "     \n",
    "    print(\"f_beta:\",f_beta.round(2),\"beta:\",b)\n",
    "    \n",
    "\n",
    "bagging_ensemble(extra_trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 60 estimators:\n",
      "test_recall : 0.74\n",
      "score_time : 5.34\n",
      "test_precision : 0.71\n",
      "test_f1 : 0.73\n",
      "test_accuracy : 0.96\n",
      "fit_time : 48.52\n",
      "test_roc_auc : 0.96\n",
      "f_beta: 0.72 beta: 0.5\n",
      "Results for 80 estimators:\n",
      "test_recall : 0.73\n",
      "score_time : 6.78\n",
      "test_precision : 0.72\n",
      "test_f1 : 0.72\n",
      "test_accuracy : 0.96\n",
      "fit_time : 62.58\n",
      "test_roc_auc : 0.96\n",
      "f_beta: 0.72 beta: 0.5\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost model\n",
    "num_estimators = [60,80]\n",
    "\n",
    "for i in num_estimators:\n",
    "    ada_boost = AdaBoostClassifier(n_estimators=i, random_state=12)\n",
    "    scores = cross_validate(ada_boost, x, y, cv=5,scoring=('accuracy', 'f1', \"roc_auc\",\"precision\",\"recall\"))\n",
    "    print(\"Results for {} estimators:\".format(i))\n",
    "    for i in scores:\n",
    "        print(i,\":\",scores[i].mean().round(2))\n",
    "    \n",
    "    b = 0.5\n",
    "    f_beta = (1 + b**2) * ((scores[\"test_precision\"].mean()*scores[\"test_recall\"].mean())/((b**2 * scores[\"test_precision\"].mean()) + scores        [\"test_recall\"].mean()))\n",
    "     \n",
    "    print(\"f_beta:\",f_beta.round(2),\"beta:\",b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time : 24.56\n",
      "score_time : 1.72\n",
      "test_accuracy : 0.95\n",
      "test_f1 : 0.53\n",
      "test_roc_auc : 0.9\n",
      "test_precision : 0.71\n",
      "test_recall : 0.42\n",
      "f_beta: 0.62 beta: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Voting Model\n",
    "voting_clf = VotingClassifier(estimators=[('NB', NB_clf), ('DTree', DTree_clf), ('LogReg', LogReg_clf)], voting='soft')\n",
    "scores = cross_validate(voting_clf, x, y, cv=5,scoring=('accuracy', 'f1', \"roc_auc\",\"precision\",\"recall\"))\n",
    "\n",
    "for i in scores:\n",
    "    print(i,\":\",scores[i].mean().round(2))\n",
    "    \n",
    "b = 0.5\n",
    "f_beta = (1 + b**2) * ((scores[\"test_precision\"].mean()*scores[\"test_recall\"].mean())/((b**2 * scores[\"test_precision\"].mean()) + scores        [\"test_recall\"].mean()))\n",
    "     \n",
    "print(\"f_beta:\",f_beta.round(2),\"beta:\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_recall : 0.63\n",
      "score_time : 37.87\n",
      "test_precision : 0.69\n",
      "test_f1 : 0.66\n",
      "test_accuracy : 0.96\n",
      "fit_time : 227.75\n",
      "test_roc_auc : 0.91\n",
      "f_beta: 0.68 beta: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Stacking Model\n",
    "LogReg_clf = LogisticRegression(C = 3.567092003128319)\n",
    "NB_clf = GaussianNB()\n",
    "DTree_clf = DecisionTreeClassifier()\n",
    "estimators = [('NB', NB_clf), ('DTree', DTree_clf), (\"LogReg\",LogReg_clf)]\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=RandomForestClassifier())\n",
    "scores = cross_validate(stacking_clf, x, y, cv=2,scoring=('accuracy', 'f1', \"roc_auc\",\"precision\",\"recall\"))\n",
    "\n",
    "for i in scores:\n",
    "    print(i,\":\",scores[i].mean().round(2))\n",
    "    \n",
    "b = 0.5\n",
    "f_beta = (1 + b**2) * ((scores[\"test_precision\"].mean()*scores[\"test_recall\"].mean())/((b**2 * scores[\"test_precision\"].mean()) + scores        [\"test_recall\"].mean()))\n",
    "     \n",
    "print(\"f_beta:\",f_beta.round(2),\"beta:\",b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  | Bagging   |Boosting  |Stacking  |\n",
    "|------|------|-----|-----|\n",
    "|  Base Classifier  | DecesionTree|AdaBoost|DecesionTree,LogReg,NaiveBayes,RandomForest|\n",
    "|  Precision  | 0.68|0.72|0.69|\n",
    "| Recall   | 0.64|0.73|0.63|\n",
    "|   Fb b=0.5 | 0.67|0.72|0.68|\n",
    "|   AUC under ROC | 0.92|0.96|0.91|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting model by far outpreformed others, Its the best model we have for now, also it was faster to compute than others\n",
    "# models in Q3, If increase number of estimators in Stacking or Bagging it might increase performance as well,\n",
    "# but it requires more powerfull hardware than in my disposal. Boosting algorithms was a king in a Kaggle for a reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Question 4] Build Ensemble Models with External Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting external data<br/>\n",
    "https://www.irs.gov/pub/irs-soi/16zpallagi.csv<br/>\n",
    "more details:<br/>\n",
    "https://www.irs.gov/statistics/soi-tax-stats-individual-income-tax-statistics-2016-zip-code-data-soi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('16zpallagi.csv', 'r')\n",
    "f.readline()\n",
    "count = {}\n",
    "for l in f.readlines():\n",
    "    s = l.split(',')\n",
    "    if s[2] == '0':\n",
    "        count[s[1], int(s[3])] = int(s[4])\n",
    "    else:\n",
    "        count['%05d' % int(s[2]), int(s[3])] = int(s[4])\n",
    "agg_count = {}\n",
    "for k, v in count.items():\n",
    "    if k[0][:3] not in agg_count:\n",
    "        agg_count[k[0][:3]] = [0] * 7\n",
    "    agg_count[k[0][:3]][k[1]] += v\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume incomes bracketed are [12500, 37500, 62500, 87500, 150000, 400000]\n",
    "# 1 = $1 under $25,000\n",
    "# 2 = $25,000 under $50,000\n",
    "# 3 = $50,000 under $75,000\n",
    "# 4 = $75,000 under $100,000\n",
    "# 5 = $100,000 under $200,000\n",
    "# 6 = $200,000 or more\n",
    "\n",
    "bracket_income = [0, 12500, 37500, 62500, 87500, 150000, 400000]\n",
    "estimated_zip_income = {}\n",
    "for k, v in agg_count.items():\n",
    "    sumn, sumd = 0, 0\n",
    "    for i in range(1, 7):\n",
    "        sumn += bracket_income[i] * v[i]\n",
    "        sumd += v[i]\n",
    "    estimated_zip_income[k] = sumn / sumd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved.insert(4, 'estimated_income', approved[['zip3', 'state']].apply(lambda x: estimated_zip_income[x[0]] if x[0] in estimated_zip_income else estimated_zip_income[x[1]] if x[1] in estimated_zip_income else 0, axis = 1))\n",
    "rejected.insert(4, 'estimated_income', rejected[['zip3', 'state']].apply(lambda x: estimated_zip_income[x[0]] if x[0] in estimated_zip_income else estimated_zip_income[x[1]] if x[1] in estimated_zip_income else 0, axis = 1))\n",
    "data_pos = approved.drop(['zip3', 'state'], axis = 1).values\n",
    "data_neg = rejected.drop(['zip3', 'state'], axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([approved,rejected])\n",
    "merged = merged.drop([\"zip3\",\"state\"], axis = 1)\n",
    "merged.head(1)\n",
    "x = merged.iloc[:,:-1]\n",
    "y = merged[\"approved\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 20 estimators:\n",
      "fit_time : 32.92\n",
      "score_time : 3.75\n",
      "test_accuracy : 0.96\n",
      "test_f1 : 0.71\n",
      "test_roc_auc : 0.95\n",
      "test_precision : 0.71\n",
      "test_recall : 0.71\n",
      "f_beta: 0.71 beta: 0.5\n",
      "Results for 40 estimators:\n",
      "fit_time : 57.73\n",
      "score_time : 5.71\n",
      "test_accuracy : 0.96\n",
      "test_f1 : 0.72\n",
      "test_roc_auc : 0.96\n",
      "test_precision : 0.71\n",
      "test_recall : 0.73\n",
      "f_beta: 0.71 beta: 0.5\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost model\n",
    "num_estimators = [20, 40]\n",
    "\n",
    "for i in num_estimators:\n",
    "    ada_boost = AdaBoostClassifier(n_estimators=i, random_state=12)\n",
    "    scores = cross_validate(ada_boost, x, y, cv=5,scoring=('accuracy', 'f1', \"roc_auc\",\"precision\",\"recall\"))\n",
    "    print(\"Results for {} estimators:\".format(i))\n",
    "    for i in scores:\n",
    "        print(i,\":\",scores[i].mean().round(2))\n",
    "    \n",
    "    b = 0.5\n",
    "    f_beta = (1 + b**2) * ((scores[\"test_precision\"].mean()*scores[\"test_recall\"].mean())/((b**2 * scores[\"test_precision\"].mean()) + scores        [\"test_recall\"].mean()))\n",
    "     \n",
    "    print(\"f_beta:\",f_beta.round(2),\"beta:\",b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time : 15.46\n",
      "score_time : 1.36\n",
      "test_accuracy : 0.95\n",
      "test_f1 : 0.47\n",
      "test_roc_auc : 0.87\n",
      "test_precision : 0.75\n",
      "test_recall : 0.35\n",
      "f_beta: 0.61 beta: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Voting Model\n",
    "voting_clf = VotingClassifier(estimators=[('NB', NB_clf), ('DTree', DTree_clf), ('LogReg', LogReg_clf)], voting='soft')\n",
    "scores = cross_validate(voting_clf, x, y, cv=5,scoring=('accuracy', 'f1', \"roc_auc\",\"precision\",\"recall\"))\n",
    "\n",
    "for i in scores:\n",
    "    print(i,\":\",scores[i].mean().round(2))\n",
    "    \n",
    "b = 0.5\n",
    "f_beta = (1 + b**2) * ((scores[\"test_precision\"].mean()*scores[\"test_recall\"].mean())/((b**2 * scores[\"test_precision\"].mean()) + scores        [\"test_recall\"].mean()))\n",
    "     \n",
    "print(\"f_beta:\",f_beta.round(2),\"beta:\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_recall : 0.56\n",
      "score_time : 41.63\n",
      "test_precision : 0.67\n",
      "test_f1 : 0.61\n",
      "test_accuracy : 0.95\n",
      "fit_time : 234.7\n",
      "test_roc_auc : 0.89\n",
      "f_beta: 0.65 beta: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Stacking Model\n",
    "LogReg_clf = LogisticRegression(C = 3.567092003128319)\n",
    "NB_clf = GaussianNB()\n",
    "DTree_clf = DecisionTreeClassifier()\n",
    "estimators = [('NB', NB_clf), ('DTree', DTree_clf), (\"LogReg\",LogReg_clf)]\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=RandomForestClassifier())\n",
    "scores = cross_validate(stacking_clf, x, y, cv=2,scoring=('accuracy', 'f1', \"roc_auc\",\"precision\",\"recall\"))\n",
    "\n",
    "for i in scores:\n",
    "    print(i,\":\",scores[i].mean().round(2))\n",
    "    \n",
    "b = 0.5\n",
    "f_beta = (1 + b**2) * ((scores[\"test_precision\"].mean()*scores[\"test_recall\"].mean())/((b**2 * scores[\"test_precision\"].mean()) + scores        [\"test_recall\"].mean()))\n",
    "     \n",
    "print(\"f_beta:\",f_beta.round(2),\"beta:\",b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=20,\n",
      "                  random_state=12)\n",
      "fit_time : 173.86\n",
      "score_time : 5.25\n",
      "test_accuracy : 0.96\n",
      "test_f1 : 0.68\n",
      "test_roc_auc : 0.93\n",
      "test_precision : 0.73\n",
      "test_recall : 0.64\n",
      "f_beta: 0.71 beta: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Bagging Decesion Tree Classifier\n",
    "\n",
    "\n",
    "DTree_clf = DecisionTreeClassifier()\n",
    "\n",
    "dtree_bagging_model = BaggingClassifier(base_estimator=DTree_clf, n_estimators=20, random_state=12)\n",
    "\n",
    "\n",
    "def bagging_ensemble(model):\n",
    "    \n",
    "    scores = cross_validate(model, x, y, cv=5,scoring=('accuracy', 'f1', \"roc_auc\",\"precision\",\"recall\"))\n",
    "    print(model)\n",
    "                          \n",
    "    for i in scores:\n",
    "        print(i,\":\",scores[i].mean().round(2))\n",
    "    \n",
    "    b = 0.5\n",
    "    f_beta = (1 + b**2) * ((scores[\"test_precision\"].mean()*scores[\"test_recall\"].mean())/((b**2 * scores[\"test_precision\"].mean()) + scores        [\"test_recall\"].mean()))\n",
    "     \n",
    "    print(\"f_beta:\",f_beta.round(2),\"beta:\",b)\n",
    "    \n",
    "\n",
    "\n",
    "bagging_ensemble(dtree_bagging_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=GaussianNB(), n_estimators=50, random_state=12)\n",
      "fit_time : 49.69\n",
      "score_time : 21.14\n",
      "test_accuracy : 0.95\n",
      "test_f1 : 0.54\n",
      "test_roc_auc : 0.84\n",
      "test_precision : 0.67\n",
      "test_recall : 0.46\n",
      "f_beta: 0.61 beta: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Baggig Naive Bayes Classifier\n",
    "\n",
    "\n",
    "NB_clf = GaussianNB()\n",
    "nb_bagging_model = BaggingClassifier(base_estimator=NB_clf, n_estimators=50, random_state=12)\n",
    "\n",
    "\n",
    "def bagging_ensemble(model):    \n",
    "    scores = cross_validate(model, x, y, cv=5,scoring=('accuracy', 'f1', \"roc_auc\",\"precision\",\"recall\"))\n",
    "    print(model)\n",
    "                          \n",
    "    for i in scores:\n",
    "        print(i,\":\",scores[i].mean().round(2))\n",
    "    \n",
    "    b = 0.5\n",
    "    f_beta = (1 + b**2) * ((scores[\"test_precision\"].mean()*scores[\"test_recall\"].mean())/((b**2 * scores[\"test_precision\"].mean()) + scores        [\"test_recall\"].mean()))\n",
    "     \n",
    "    print(\"f_beta:\",f_beta.round(2),\"beta:\",b)\n",
    "    \n",
    "\n",
    "\n",
    "bagging_ensemble(nb_bagging_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=LogisticRegression(C=3.567092003128319),\n",
      "                  n_estimators=5, random_state=12)\n",
      "fit_time : 45.31\n",
      "score_time : 1.23\n",
      "test_accuracy : 0.94\n",
      "test_f1 : 0.45\n",
      "test_roc_auc : 0.86\n",
      "test_precision : 0.7\n",
      "test_recall : 0.33\n",
      "f_beta: 0.58 beta: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Bagging Logistic Regression Classifier\n",
    "x_scaled = MinMaxScaler().fit_transform(x)\n",
    "LogReg_clf = LogisticRegression(C = 3.567092003128319)\n",
    "\n",
    "logreg_bagging_model = BaggingClassifier(base_estimator=LogReg_clf, n_estimators=5, random_state=12)\n",
    "\n",
    "\n",
    "def bagging_ensemble(model):\n",
    "    \n",
    "    scores = cross_validate(model, x_scaled, y, cv=5,scoring=('accuracy', 'f1', \"roc_auc\",\"precision\",\"recall\"))\n",
    "    print(model)\n",
    "                          \n",
    "    for i in scores:\n",
    "        print(i,\":\",scores[i].mean().round(2))\n",
    "    \n",
    "    b = 0.5\n",
    "    f_beta = (1 + b**2) * ((scores[\"test_precision\"].mean()*scores[\"test_recall\"].mean())/((b**2 * scores[\"test_precision\"].mean()) + scores        [\"test_recall\"].mean()))\n",
    "     \n",
    "    print(\"f_beta:\",f_beta.round(2),\"beta:\",b)\n",
    "    \n",
    "\n",
    "bagging_ensemble(logreg_bagging_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  | Bagging   |Boosting  |Stacking  |\n",
    "|------|------|-----|-----|\n",
    "|  Base Classifier  | DecesionTree|AdaBoost|DecesionTree,LogReg,NaiveBayes,RandomForest|\n",
    "|  Precision  | 0.73|0.71|0.67|\n",
    "| Recall   | 0.64|0.73|0.56|\n",
    "|   Fb b=0.5 | 0.71|0.71|0.65|\n",
    "|   AUC under ROC | 0.93|0.96|0.89|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking model became worse, Boosting aprox. same, Bagging has decent leap in performance but still Boosting model is\n",
    "# preferable even though Fb are same, Boosting model has higher AUC."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
